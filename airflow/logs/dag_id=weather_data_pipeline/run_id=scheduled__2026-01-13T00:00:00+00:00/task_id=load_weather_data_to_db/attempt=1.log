[2026-01-16T05:31:46.154+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.load_weather_data_to_db scheduled__2026-01-13T00:00:00+00:00 [queued]>
[2026-01-16T05:31:46.170+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.load_weather_data_to_db scheduled__2026-01-13T00:00:00+00:00 [queued]>
[2026-01-16T05:31:46.170+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2026-01-16T05:31:46.192+0000] {taskinstance.py:1380} INFO - Executing <Task(BashOperator): load_weather_data_to_db> on 2026-01-13 00:00:00+00:00
[2026-01-16T05:31:46.199+0000] {standard_task_runner.py:57} INFO - Started process 349 to run task
[2026-01-16T05:31:46.204+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'load_weather_data_to_db', 'scheduled__2026-01-13T00:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/weather_scheduler.py', '--cfg-path', '/tmp/tmpa5n2ct28']
[2026-01-16T05:31:46.208+0000] {standard_task_runner.py:85} INFO - Job 26: Subtask load_weather_data_to_db
[2026-01-16T05:31:46.289+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.load_weather_data_to_db scheduled__2026-01-13T00:00:00+00:00 [running]> on host 84a850d23116
[2026-01-16T05:31:46.440+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='pangorin' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='load_weather_data_to_db' AIRFLOW_CTX_EXECUTION_DATE='2026-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2026-01-13T00:00:00+00:00'
[2026-01-16T05:31:46.444+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2026-01-16T05:31:46.447+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /opt/***/scripts/load.py']
[2026-01-16T05:31:46.463+0000] {subprocess.py:86} INFO - Output:
[2026-01-16T05:31:47.877+0000] {subprocess.py:93} INFO - Starting load process...
[2026-01-16T05:31:47.879+0000] {subprocess.py:93} INFO - Error: No processed files found matching 'data/processed/processed_weather_*.csv'.
[2026-01-16T05:31:47.880+0000] {subprocess.py:93} INFO - Please run (or rerun) transform script.
[2026-01-16T05:31:47.998+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2026-01-16T05:31:48.064+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=weather_data_pipeline, task_id=load_weather_data_to_db, execution_date=20260113T000000, start_date=20260116T053146, end_date=20260116T053148
[2026-01-16T05:31:48.106+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2026-01-16T05:31:48.151+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2026-01-16T05:39:08.680+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.load_weather_data_to_db scheduled__2026-01-13T00:00:00+00:00 [queued]>
[2026-01-16T05:39:08.704+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.load_weather_data_to_db scheduled__2026-01-13T00:00:00+00:00 [queued]>
[2026-01-16T05:39:08.706+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2026-01-16T05:39:08.739+0000] {taskinstance.py:1380} INFO - Executing <Task(BashOperator): load_weather_data_to_db> on 2026-01-13 00:00:00+00:00
[2026-01-16T05:39:08.751+0000] {standard_task_runner.py:57} INFO - Started process 225 to run task
[2026-01-16T05:39:08.758+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'load_weather_data_to_db', 'scheduled__2026-01-13T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/weather_scheduler.py', '--cfg-path', '/tmp/tmp7_4pjz_h']
[2026-01-16T05:39:08.765+0000] {standard_task_runner.py:85} INFO - Job 7: Subtask load_weather_data_to_db
[2026-01-16T05:39:08.941+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.load_weather_data_to_db scheduled__2026-01-13T00:00:00+00:00 [running]> on host d5e9cd3f2712
[2026-01-16T05:39:09.227+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='pangorin' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='load_weather_data_to_db' AIRFLOW_CTX_EXECUTION_DATE='2026-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2026-01-13T00:00:00+00:00'
[2026-01-16T05:39:09.234+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2026-01-16T05:39:09.236+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /opt/***/scripts/load.py']
[2026-01-16T05:39:09.269+0000] {subprocess.py:86} INFO - Output:
[2026-01-16T05:39:11.518+0000] {subprocess.py:93} INFO - Starting load process...
[2026-01-16T05:39:11.521+0000] {subprocess.py:93} INFO - Error: No processed files found matching 'data/processed/processed_weather_*.csv'.
[2026-01-16T05:39:11.527+0000] {subprocess.py:93} INFO - Please run (or rerun) transform script.
[2026-01-16T05:39:11.720+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2026-01-16T05:39:11.882+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=weather_data_pipeline, task_id=load_weather_data_to_db, execution_date=20260113T000000, start_date=20260116T053908, end_date=20260116T053911
[2026-01-16T05:39:11.948+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2026-01-16T05:39:12.025+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2026-01-16T05:54:11.945+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.load_weather_data_to_db scheduled__2026-01-13T00:00:00+00:00 [queued]>
[2026-01-16T05:54:11.965+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.load_weather_data_to_db scheduled__2026-01-13T00:00:00+00:00 [queued]>
[2026-01-16T05:54:11.965+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2026-01-16T05:54:11.998+0000] {taskinstance.py:1380} INFO - Executing <Task(BashOperator): load_weather_data_to_db> on 2026-01-13 00:00:00+00:00
[2026-01-16T05:54:12.008+0000] {standard_task_runner.py:57} INFO - Started process 224 to run task
[2026-01-16T05:54:12.014+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'load_weather_data_to_db', 'scheduled__2026-01-13T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/weather_scheduler.py', '--cfg-path', '/tmp/tmpo7fjx2ml']
[2026-01-16T05:54:12.021+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask load_weather_data_to_db
[2026-01-16T05:54:12.154+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.load_weather_data_to_db scheduled__2026-01-13T00:00:00+00:00 [running]> on host 7eba5050a014
[2026-01-16T05:54:12.325+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='pangorin' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='load_weather_data_to_db' AIRFLOW_CTX_EXECUTION_DATE='2026-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2026-01-13T00:00:00+00:00'
[2026-01-16T05:54:12.330+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2026-01-16T05:54:12.332+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /opt/***/scripts/load.py']
[2026-01-16T05:54:12.347+0000] {subprocess.py:86} INFO - Output:
[2026-01-16T05:54:16.906+0000] {subprocess.py:93} INFO - Starting load process...
[2026-01-16T05:54:16.907+0000] {subprocess.py:93} INFO - Searching for files at: /opt/***/data/processed/processed_weather_*.csv
[2026-01-16T05:54:16.909+0000] {subprocess.py:93} INFO - Found latest data file: /opt/***/data/processed/processed_weather_data_20260116_055409.csv
[2026-01-16T05:54:16.914+0000] {subprocess.py:93} INFO - Successfully connected to MySQL database.
[2026-01-16T05:54:16.919+0000] {subprocess.py:93} INFO - --------------------------------------------------
[2026-01-16T05:54:16.921+0000] {subprocess.py:93} INFO - Successfully loaded 110 records into the weather_readings.
[2026-01-16T05:54:17.278+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2026-01-16T05:54:17.367+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=weather_data_pipeline, task_id=load_weather_data_to_db, execution_date=20260113T000000, start_date=20260116T055411, end_date=20260116T055417
[2026-01-16T05:54:17.417+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2026-01-16T05:54:17.458+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2026-01-16T06:06:46.114+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.load_weather_data_to_db scheduled__2026-01-13T00:00:00+00:00 [queued]>
[2026-01-16T06:06:46.149+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.load_weather_data_to_db scheduled__2026-01-13T00:00:00+00:00 [queued]>
[2026-01-16T06:06:46.152+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2026-01-16T06:06:46.199+0000] {taskinstance.py:1380} INFO - Executing <Task(BashOperator): load_weather_data_to_db> on 2026-01-13 00:00:00+00:00
[2026-01-16T06:06:46.213+0000] {standard_task_runner.py:57} INFO - Started process 220 to run task
[2026-01-16T06:06:46.219+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'load_weather_data_to_db', 'scheduled__2026-01-13T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/weather_scheduler.py', '--cfg-path', '/tmp/tmpyykv7a87']
[2026-01-16T06:06:46.228+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask load_weather_data_to_db
[2026-01-16T06:06:46.358+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.load_weather_data_to_db scheduled__2026-01-13T00:00:00+00:00 [running]> on host 5f9f65985556
[2026-01-16T06:06:46.633+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='pangorin' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='load_weather_data_to_db' AIRFLOW_CTX_EXECUTION_DATE='2026-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2026-01-13T00:00:00+00:00'
[2026-01-16T06:06:46.639+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2026-01-16T06:06:46.645+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /opt/***/scripts/load.py']
[2026-01-16T06:06:46.664+0000] {subprocess.py:86} INFO - Output:
[2026-01-16T06:06:50.501+0000] {subprocess.py:93} INFO - Starting load process...
[2026-01-16T06:06:50.505+0000] {subprocess.py:93} INFO - Searching for files at: /opt/***/data/processed/processed_weather_*.csv
[2026-01-16T06:06:50.509+0000] {subprocess.py:93} INFO - Found latest data file: /opt/***/data/processed/processed_weather_data_20260116_060642.csv
[2026-01-16T06:06:50.513+0000] {subprocess.py:93} INFO - Successfully connected to MySQL database.
[2026-01-16T06:06:50.522+0000] {subprocess.py:93} INFO - --------------------------------------------------
[2026-01-16T06:06:50.529+0000] {subprocess.py:93} INFO - Successfully loaded 120 records into the weather_readings.
[2026-01-16T06:06:50.792+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2026-01-16T06:06:50.855+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=weather_data_pipeline, task_id=load_weather_data_to_db, execution_date=20260113T000000, start_date=20260116T060646, end_date=20260116T060650
[2026-01-16T06:06:50.922+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2026-01-16T06:06:50.966+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
