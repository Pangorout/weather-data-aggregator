services:
  airflow:
    build: .
    container_name: airflow_scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      # Override .env file so Airflow connects to the correct Docker network
      - DB_HOST=host.docker.internal
      - DB_PORT=3307
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./scripts:/opt/airflow/scripts
      - ./data:/opt/airflow/data
      - ./.env:/opt/airflow/.env
    ports:
      - "8080:8080"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    command: >
      bash -c "airflow db init &&
      airflow users create --username ${AIRFLOW_USERNAME} --password ${AIRFLOW_PASSWORD} --firstname User --lastname Admin --role Admin --email ${AIRFLOW_EMAIL} &&
      airflow webserver -D &&
      airflow scheduler"
    depends_on:
      postgres:
        condition: service_healthy
  
  postgres:
    image: postgres:13-alpine
    container_name: airflow_db
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 5s
      retries: 5